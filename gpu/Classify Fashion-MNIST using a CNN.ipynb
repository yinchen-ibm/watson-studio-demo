{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Classify the Fashion-MNIST data set using a CNN in a GPU powered notebook\n\nThis notebook guides you through the basic steps in constructing a Convolutional Neural Network with the Keras and TensorFlow libraries in IBM Watson Studio, including training the model directly in the notebook using a GPU environment. In the notebook, you will learn how to save the model for future inference, deploy it and score it using the IBM Watson Machine Learning service.\n\nSome familiarity with Python is recommended. This notebook runs on Python 3.6 with Tensorflow 1.12.\n\n## Contents\n\n\n1.\t[Fashion-MNIST data set](#dataset)\n2.\t[Import the data sets](#importdata)\n3.\t[Prepare the data sets](#preparedata)\n4.\t[Define the neural network](#neuralNetwork)\n5.\t[Train the network](#train)\n6.\t[Save and Deploy](#deploy)\n7.\t[Summary](#summary)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"dataset\"></a>\n<div><img src=\"https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png\", width=450, height=450, align = 'right', style=\"margin:10px 35px\"></div>\n\n## 1. Fashion MNIST data set\nYou might already have heard of the original <a href=\"http://yann.lecun.com/exdb/mnist/\" target=\"_blank\" rel=\"noopener no referrer\">MNIST data set</a> which contains many handwritten digits. The Fashion-MNIST data set, which you will use in this notebook, is a replacement of the original data set of handwritten digits, which has been overused and is no longer representative for benchmarking machine learning algorithms. The Fashion MNIST data set contains images of Zalando articles. It comprises a training set of 60,000 images and a test set of 10,000 images. Each example in the training and test sets is a 28x28 grayscale image, associated with a label from 10 classes. The first column consists of the class labels (as you can see in the following section) and represents the article of clothing. The remaining columns contain the pixel-values of the associated image. You can read more about the data set <a href=\"https://github.com/zalandoresearch/fashion-mnist\" target=\"_blank\" rel=\"noopener no referrer\">here</a>.\n\n### Labels\n\nEach training and test example is assigned to one of the following labels:\n\n| **Label** | **Description** |\n|:----------|:----------------|\n|0 \t        |T-shirt/top      |\n|1 \t        |Trouser          |\n|2          |Pullover         |\n|3 \t        |Dress            |\n|4 \t        |Coat             |\n|5 \t        |Sandal           |\n|6 \t        |Shirt            |\n|7 \t        |Sneaker          |\n|8          |Bag              |\n|9          |Ankle boot       |\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"importdata\"></a>\n\n## 2. Import the data sets\nTo get the Fashion-MNIST training and test data sets:\n\n- Go to [this link](https://www.kaggle.com/zalando-research/fashionmnist) and then download the following data sets in CSV format:\n\n    - `fashion-mnist_train.csv`\n    - `fashion-mnist_test.csv`\n    \n- Save the CSV files to your local file system.\n\n- Load the data files to use in the notebook:\n\n   - On the notebook [action bar](https://dataplatform.cloud.ibm.com/docs/content/analyze-data/parts-of-a-notebook.html?audience=wdp&context=wdp#notebook-action-bar) at the top right corner, click the data icon.\n   - In the data panel that pops up, drag and drop or click **browse** to load the two NMIST data sets in your local file system.\n\nThe data files are listed on the Files tab and are stored in object storage.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Insert code to access the training data set\nTo access the training data in the `fashion-mnist_train.csv` file in your notebook, select the following empty cell, in the right hand side data panel click **Insert to code** below the train CSV file, and then **Insert pandas DataFrame**. After the code is loaded, run the cell to read the CSV file.\n\n**Note**: The name of the returned dataframe will be something like df_data_1. Rename it to **train_df**. The variable **train_df** is used through out the remaining notebook to represent the training data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 1, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 785 columns</p>\n</div>", 
                        "text/plain": "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      2       0       0       0       0       0       0       0       0   \n1      9       0       0       0       0       0       0       0       0   \n2      6       0       0       0       0       0       0       0       5   \n3      0       0       0       0       1       2       0       0       0   \n4      3       0       0       0       0       0       0       0       0   \n\n   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0    ...            0         0         0         0         0   \n1       0    ...            0         0         0         0         0   \n2       0    ...            0         0         0        30        43   \n3       0    ...            3         0         0         0         0   \n4       0    ...            0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  pixel784  \n0         0         0         0         0         0  \n1         0         0         0         0         0  \n2         0         0         0         0         0  \n3         1         0         0         0         0  \n4         0         0         0         0         0  \n\n[5 rows x 785 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "### Insert code to access the test data set\n\nTo access the test data in the `fashion-mnist_test.csv` file in your notebook, select the following empty cell, in the right hand side data panel click **Insert to code** below the test CSV file, and then **Insert pandas DataFrame**. After the code is loaded, run the cell to read the CSV file.\n\n**Note**: The name of the returned dataframe will be something like df_data_1. Rename it to **test_df**. The variable **test_df** is used through out the remaining notebook to represent the test data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 785 columns</p>\n</div>", 
                        "text/plain": "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      2       0       0       0       0       0       0       0       0   \n1      9       0       0       0       0       0       0       0       0   \n2      6       0       0       0       0       0       0       0       5   \n3      0       0       0       0       1       2       0       0       0   \n4      3       0       0       0       0       0       0       0       0   \n\n   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0    ...            0         0         0         0         0   \n1       0    ...            0         0         0         0         0   \n2       0    ...            0         0         0        30        43   \n3       0    ...            3         0         0         0         0   \n4       0    ...            0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  pixel784  \n0         0         0         0         0         0  \n1         0         0         0         0         0  \n2         0         0         0         0         0  \n3         1         0         0         0         0  \n4         0         0         0         0         0  \n\n[5 rows x 785 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "\nbody = client_73ae0289eca54f3b800daa1c63d6fc43.get_object(Bucket='gpunotebookdemo-donotdelete-pr-skkqjvpa902st8',Key='fashion-mnist_train.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ntest_df = pd.read_csv(body)\ntest_df.head()\n\n"
        }, 
        {
            "source": "<a id=\"preparedata\"></a>\n## 3. Prepare the data sets\nLet's begin the data preparation by normalizing the data dimensions so that they are of approximately the same scale.  Before you can start with this, you need to import the libraries you will be using and then extract the data from the previously loaded data frames into numpy arrays.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\nfrom sklearn.model_selection import train_test_split\n\ntrain_data = np.array(train_df, dtype='float32')\ntest_data = np.array(test_df, dtype='float32')\n\nx_train = train_data[:, 1:] / 255\ny_train = train_data[:, 0]\n\nx_test = test_data[:, 1:] / 255\ny_test = test_data[:, 0]"
        }, 
        {
            "source": "### Split into training, validation and test data sets\nSplit the training data set comprising 60,000 images of different articles of clothing into a training set and a validation set. The training set should contain 80% of the training data set and the validation set 20%.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Shape of the training data set (Features): (48000, 784)\nShape of the training data set (Labels): (48000,)\nShape of the validation data set (Features): (12000, 784)\nShape of the validation data set (Labels): (12000,)\n"
                }
            ], 
            "source": "x_train, x_validate, y_train, y_validate = train_test_split(\n    x_train, y_train, test_size = 0.2, random_state=44)\nprint(\"Shape of the training data set (Features): {}\".format(x_train.shape))\nprint(\"Shape of the training data set (Labels): {}\".format(y_train.shape))\nprint(\"Shape of the validation data set (Features): {}\".format(x_validate.shape))\nprint(\"Shape of the validation data set (Labels): {}\".format(y_validate.shape))"
        }, 
        {
            "source": "### Visualize a few articles\nUse the imshow() function in the matplotlib library to visualize the greyscale images.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<function matplotlib.pyplot.show(*args, **kw)>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import matplotlib.pyplot as plt\nimage = x_train[10, :].reshape((28,28))\nplt.imshow(image)\nplt.show"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 7, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<function matplotlib.pyplot.show(*args, **kw)>"
                    }, 
                    "output_type": "execute_result"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "image = x_train[40000, :].reshape((28,28))\nplt.imshow(image)\nplt.show"
        }, 
        {
            "source": "<a id=\"neuralNetwork\"></a>\n\n## 4. Define the neural network\n\nNow you will learn how to create a Convolution Neural Network that recognizes Zalando articles in images. Convolutional Neural Networks, or commonly known as CNNs, are class of deep neural networks that is primarily used for visual recognition tasks. In this notebook, you will create a simple CNN based classification model. You will use the Keras framework to build the model. <a href=\"https://keras.io/\" >Keras</a> is a high-level neural networks API, written in Python.\n\nImport the Keras library and then reshape the data sets.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n"
                }
            ], 
            "source": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback\n\nim_rows = 28\nim_cols = 28\nim_shape = (im_rows, im_cols, 1)\nx_train = x_train.reshape(x_train.shape[0], *im_shape)\nx_test = x_test.reshape(x_test.shape[0], *im_shape)\nx_validate = x_validate.reshape(x_validate.shape[0], *im_shape)"
        }, 
        {
            "source": "### Define the various layers in the network\nThe CNN model you create will have a convolution layer followed by a pooling layer and then a dropout layer. The output of the dropout layer is flattened into a fully connected layer. The last layer is a dense layer with Softmax activation that classifies the 10 categories of the clothing data images in the Fashion-MNIST data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cnn_model = Sequential([\n    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=im_shape),\n    MaxPool2D(pool_size=(2,2)),\n    Dropout(0.2),\n    Flatten(),\n    Dense(32, activation='relu'),\n    Dense(10, activation='softmax')\n])"
        }, 
        {
            "source": "Before you can start training the model, you need to compile it. For this you will use the model.compile() function. Specify a loss function, an optimizer and the metrics.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cnn_model.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer=Adam(lr=0.001),\n    metrics=['accuracy']\n)"
        }, 
        {
            "source": "<a id=\"train\" ></a>\n## 5. Train the neural network\nThe following code cell starts the model training process, also referred to as model fitting. You will train the model in batches of 200 images in 20 epochs.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 48000 samples, validate on 12000 samples\nEpoch 1/20\n48000/48000 [==============================] - 9s 184us/step - loss: 0.6196 - acc: 0.7866 - val_loss: 0.4391 - val_acc: 0.8449\nEpoch 2/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.4103 - acc: 0.8563 - val_loss: 0.3770 - val_acc: 0.8653\nEpoch 3/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.3632 - acc: 0.8731 - val_loss: 0.3442 - val_acc: 0.8761\nEpoch 4/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.3315 - acc: 0.8850 - val_loss: 0.3145 - val_acc: 0.8906\nEpoch 5/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.3092 - acc: 0.8925 - val_loss: 0.3025 - val_acc: 0.8895\nEpoch 6/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.2948 - acc: 0.8969 - val_loss: 0.3152 - val_acc: 0.8812\nEpoch 7/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.2801 - acc: 0.9014 - val_loss: 0.2912 - val_acc: 0.8943\nEpoch 8/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.2689 - acc: 0.9049 - val_loss: 0.2933 - val_acc: 0.8941\nEpoch 9/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.2587 - acc: 0.9085 - val_loss: 0.2792 - val_acc: 0.8992\nEpoch 10/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.2499 - acc: 0.9102 - val_loss: 0.2666 - val_acc: 0.9060\nEpoch 11/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.2390 - acc: 0.9151 - val_loss: 0.2650 - val_acc: 0.9050\nEpoch 12/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.2325 - acc: 0.9177 - val_loss: 0.2560 - val_acc: 0.9089\nEpoch 13/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.2259 - acc: 0.9194 - val_loss: 0.2569 - val_acc: 0.9054\nEpoch 14/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.2197 - acc: 0.9222 - val_loss: 0.2726 - val_acc: 0.9023\nEpoch 15/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.2126 - acc: 0.9243 - val_loss: 0.2646 - val_acc: 0.9038\nEpoch 16/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.2076 - acc: 0.9261 - val_loss: 0.2672 - val_acc: 0.9038\nEpoch 17/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.2015 - acc: 0.9280 - val_loss: 0.2567 - val_acc: 0.9077\nEpoch 18/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.1962 - acc: 0.9292 - val_loss: 0.2599 - val_acc: 0.9103\nEpoch 19/20\n48000/48000 [==============================] - 1s 19us/step - loss: 0.1900 - acc: 0.9318 - val_loss: 0.2462 - val_acc: 0.9119\nEpoch 20/20\n48000/48000 [==============================] - 1s 18us/step - loss: 0.1868 - acc: 0.9325 - val_loss: 0.2551 - val_acc: 0.9093\n"
                }, 
                {
                    "execution_count": 9, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x2b3d8c076ba8>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "cnn_model.fit(\n    x_train, y_train, batch_size=200,\n    epochs=20, verbose=1,\n    validation_data=(x_validate, y_validate)\n)"
        }, 
        {
            "source": "### Test accuracy\nTest the accuracy of the model. You will see that the model has an accuracy of over 91%.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n Test accuracy: 0.93595\n"
                }
            ], 
            "source": "score = cnn_model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])"
        }, 
        {
            "source": "### Visualize the predictions\nYou can see how well your model is performing by taking a few images from the test data set and testing how well they are recognized by the model. For this test, you will use image number 100 and 200 from the test data set. You will also visualize the images to see which articles are represented.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n Model predicts the label: [8]\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "test_img = x_test[100,:].reshape((28,28))\nplt.imshow(test_img)\ntest_img = test_img.reshape(1, *im_shape)\nprint('\\n', 'Model predicts the label:', cnn_model.predict_classes(test_img))"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n Model predicts the label: [3]\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "test_img = x_test[200,:].reshape((28,28))\nplt.imshow(test_img)\ntest_img = test_img.reshape(1, *im_shape)\nprint('\\n', 'Model predicts the label:', cnn_model.predict_classes(test_img))"
        }, 
        {
            "source": "If you check the table with labels, and compare that with the visualizations you see, it looks like the model is predicting clothing articles very well. You have successfully built a CNN with over 90% accuracy.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"deploy\" ></a>\n# 6. Deploy the model\n\nNow you can deploy this model in the Cloud and get a scoring endpoint. To deploy the model created in this notebook, you need an instance of IBM Watson Machine Learning service. You can see if a Watson Machine Learning service instance is already associated with your project by clicking the **Services** menu in Watson Studio and selecting **Watson Services**. If no service exists, create a [Watson Machine Learning service instance](https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/). \n\n\nTo get the service credentials:\n1. From the **Services** menu in Watson Studio, open **Watson Services** in a new browser tab. (This opens the Watson Services page in Watson Studio.)\n2. In the Machine Learning section, click the service instance for which you want to retrieve credentials. (This opens the service details page in IBM Cloud for the Watson Machine Learning service instance.)\n3. Click **Service credentials**. If there are no service credentials yet, click the **New credential**.\n4. Under the **ACTION** menu, click **View credentials**.\n5. Copy the credentials into the following cell.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wml_credentials = {\n  \"apikey\": \"oTW1O9BHTHDTMAfp6pzpIIz0Qt3dMefiwIpctW8425YA\",\n  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance - crn:v1:bluemix:public:pm-20:us-south:a/5efafa56ac2ecb57a93a28ca9c4ef9b6:bcac73dc-04b9-476b-a46b-cb0de69e673e::\",\n  \"iam_apikey_name\": \"auto-generated-apikey-799c74ee-248e-47b9-b947-ee787596a543\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/5efafa56ac2ecb57a93a28ca9c4ef9b6::serviceid:ServiceId-e4ddbc78-24d5-458d-8df3-f2fa458ebdb5\",\n  \"instance_id\": \"bcac73dc-04b9-476b-a46b-cb0de69e673e\",\n  \"password\": \"d0a13022-5b01-45e9-8205-8709fc6d415c\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n  \"username\": \"799c74ee-248e-47b9-b947-ee787596a543\"\n}"
        }, 
        {
            "source": "Import the watson-machine-learning-client and authenticate to the service instance.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient\nclient = WatsonMachineLearningAPIClient(wml_credentials)"
        }, 
        {
            "source": "### Store the trained model in the WML repository\nYou have  connected to the Watson Machine Learning repository using the Python package and your credentials. Publishing the model will save the model to your repository.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "keras_fashion_mnist.h5\r\n"
                }
            ], 
            "source": "cnn_model.save(\"keras_fashion_mnist.h5\")\n!tar -cvf keras_fashion_mnist.tar keras_fashion_mnist.h5\n!gzip -f keras_fashion_mnist.tar\nmodel_tar_gz = \"keras_fashion_mnist.tar.gz\"\n\nmetadata = {\n        client.repository.ModelMetaNames.AUTHOR_NAME: \"Sumit Goyal\",\n        client.repository.ModelMetaNames.NAME: 'Fashion MNIST with Keras',\n        client.repository.ModelMetaNames.FRAMEWORK_NAME: 'tensorflow',\n        client.repository.ModelMetaNames.FRAMEWORK_VERSION: '1.12',\n        client.repository.ModelMetaNames.RUNTIME_NAME: 'python',\n        client.repository.ModelMetaNames.RUNTIME_VERSION: '3.5',\n        client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [\n         {\"name\": \"keras\", \"version\": \"2.2.4\"}\n    ]\n}\nstored_model_details = client.repository.store_model(model_tar_gz, meta_props=metadata, training_data=None)"
        }, 
        {
            "source": "### Create the online deployment\nNow you will deploy the stored model as a web service.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '01ec6725-4b51-4792-a04e-26e9f8e24802' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='616017e9-2767-43a5-81dc-ed0b79ad24e3'\n------------------------------------------------------------------------------------------------\n\n\n"
                }
            ], 
            "source": "created_deployment = client.deployments.create(stored_model_details['metadata']['guid'], \"Fashion MNIST with Keras\")"
        }, 
        {
            "source": "\n\nNow you can define and print an online scoring endpoint.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/bcac73dc-04b9-476b-a46b-cb0de69e673e/deployments/616017e9-2767-43a5-81dc-ed0b79ad24e3/online\n"
                }
            ], 
            "source": "scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\nprint(scoring_endpoint)"
        }, 
        {
            "source": "### Score data\nUse the following method to run a test scoring request against the deployed model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "score_data = x_test[100].tolist()\nscoring_payload = {'values': [score_data]}"
        }, 
        {
            "source": "Use the client.deployments.score() method to run the scoring.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{\n  \"fields\": [\n    \"prediction\",\n    \"prediction_classes\",\n    \"probability\"\n  ],\n  \"values\": [\n    [\n      [\n        1.595842513779644e-05,\n        5.818360932607902e-06,\n        2.4869302706065355e-07,\n        3.647633306513853e-08,\n        1.2989552260478376e-06,\n        3.2485646117574873e-11,\n        0.00019787767087109387,\n        5.266992952890348e-10,\n        0.9997788071632385,\n        2.027643164481674e-09\n      ],\n      8,\n      [\n        1.595842513779644e-05,\n        5.818360932607902e-06,\n        2.4869302706065355e-07,\n        3.647633306513853e-08,\n        1.2989552260478376e-06,\n        3.2485646117574873e-11,\n        0.00019787767087109387,\n        5.266992952890348e-10,\n        0.9997788071632385,\n        2.027643164481674e-09\n      ]\n    ]\n  ]\n}\n"
                }
            ], 
            "source": "import json\npredictions = client.deployments.score(scoring_endpoint, scoring_payload)\nprint(json.dumps(predictions, indent=2))"
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## 7. Summary\n\nYou learned how to prepare the Fashion-MNIST data set and how to build and train a Convolutional Neural Network by using the Keras and TensorFlow libraries. By running your notebook in a GPU environment, you could do all the model training and testing directly in your notebook; you didn't have to switch to the IBM Machine Learning service to train your model. In the last section of the notebook, you learned how to save and deploy the model in the Watson Machine Learning service.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Author\n\n**Sumit Goyal** is a software engineer in the Watson Studio development team at IBM in Germany. He holds a degree in Automation and Industrial IT and is passionate about data analysis, machine learning and the ecosystem for data science.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### License - Fashion-MNIST\n\nThe Fashion-MNIST data set is licensed under the MIT License (MIT) Copyright \u00a9 [2017] Zalando SE, https://tech.zalando.com \n\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<hr>\nCopyright \u00a9 2018. This notebook and its source code are released under the terms of the MIT License.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with GPU, Tensorflow 1.12, and PyTorch 1.0", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}